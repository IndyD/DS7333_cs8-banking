{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('case_8.csv')\n",
    "## test the code with a subset of the data\n",
    "data = data[0:100]\n",
    "target = data['target']\n",
    "data.drop(['target', 'ID'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v22': 95, 'v56': 33, 'v125': 48}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find cols with over 20 categories \n",
    "cat_data = data.loc[:, data.dtypes == object]\n",
    "\n",
    "col_bin_candidates = dict()\n",
    "for col in cat_data:\n",
    "    category_count = len(data[col].value_counts())\n",
    "    if category_count > 20:\n",
    "        col_bin_candidates[col] = category_count\n",
    "        \n",
    "col_bin_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in processing the data is splitting the target column out and droping the `ID` column which adds no value to the analysis. Once this is done, an investigation is done for any categorical columns that contains a high number of categories. The categorical column counts show that column `v22` has 18210 distinct values. \n",
    "\n",
    "This can be a problem after one hot encoding as will be done farther in the analysis because it would lead to a very large, sparse matrix. In the next code block the counts for categorical variables with over 20 categories are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Visualized values for cols with over 10 categories\n",
    "for col in col_bin_candidates:\n",
    "    counts = data[col].value_counts().to_frame()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    if len(counts) < 50:\n",
    "        plt.title(\"{c} Bar Char\".format(c=col)) \n",
    "        plt.bar(counts.index, counts[col])\n",
    "    else:\n",
    "        plt.title(\"{c} Histogram\".format(c=col)) \n",
    "        plt.hist(counts[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bar charts above it seems that columns `v22` and `v113` don't have an excessive number of categories and have some spread so will be kept unaltered. Column `v125` has over 100 categories but many appear to have at least 1000 samples so this column will also be kept as unaltered. Columns `v56` and `v22` have a large categories of users with a relatively low number of users and will likely need binning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGDF    4\n",
       "QKP     2\n",
       "VZF     2\n",
       "XDX     1\n",
       "QU      1\n",
       "QHQ     1\n",
       "BMF     1\n",
       "IEE     1\n",
       "JOF     1\n",
       "AV      1\n",
       "ADDF    1\n",
       "YGJ     1\n",
       "NKE     1\n",
       "AYX     1\n",
       "ACTZ    1\n",
       "VVI     1\n",
       "FLR     1\n",
       "ABQS    1\n",
       "KEM     1\n",
       "AHPP    1\n",
       "AGXX    1\n",
       "PWR     1\n",
       "DOB     1\n",
       "IIP     1\n",
       "AGVV    1\n",
       "QKI     1\n",
       "GOI     1\n",
       "RHD     1\n",
       "CBS     1\n",
       "MQE     1\n",
       "ABJD    1\n",
       "BZT     1\n",
       "MVD     1\n",
       "ZHA     1\n",
       "SGN     1\n",
       "KBM     1\n",
       "AIN     1\n",
       "AFJK    1\n",
       "AGRM    1\n",
       "XFE     1\n",
       "UDX     1\n",
       "HUU     1\n",
       "BWJ     1\n",
       "FQ      1\n",
       "ABPH    1\n",
       "XQU     1\n",
       "NFD     1\n",
       "NGS     1\n",
       "AHBW    1\n",
       "AAJR    1\n",
       "Name: v22, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Look for bin point col v22\n",
    "data['v22'].value_counts()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection of the first 50 the value counts for column `v22` shows a dropoff in value counts after the value `HUU` with a count of 146."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BW    16\n",
       "DI     7\n",
       "DX     6\n",
       "AS     6\n",
       "DP     5\n",
       "AW     5\n",
       "CY     4\n",
       "DS     4\n",
       "BZ     4\n",
       "CN     4\n",
       "AL     3\n",
       "BJ     3\n",
       "P      3\n",
       "BV     3\n",
       "N      2\n",
       "AF     2\n",
       "BQ     2\n",
       "DO     2\n",
       "U      2\n",
       "BL     2\n",
       "DY     2\n",
       "AG     2\n",
       "DF     1\n",
       "V      1\n",
       "DN     1\n",
       "AZ     1\n",
       "DL     1\n",
       "DH     1\n",
       "R      1\n",
       "Z      1\n",
       "DJ     1\n",
       "BM     1\n",
       "BU     1\n",
       "Name: v56, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Look for bin point col v56\n",
    "data['v56'].value_counts()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar inspection of column `v56` shows a sharp dropoff after value `CF` woth 141 value counts. Based on the above, the next two code blocks will bin all categories with value counts below 140 for columns `v22` and `v56`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Bin categorical colunm based on cutoff for minmum value count\n",
    "def bin_df_col(df, col, cutoff):\n",
    "    vc = df[col].value_counts().to_frame()\n",
    "    below_cutoff = vc[vc[col] < cutoff].index\n",
    "    df.loc[(df[col].isin(below_cutoff)), col] = 'Other'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bin cols based on observations above\n",
    "data = bin_df_col(data, 'v22', 140)\n",
    "data = bin_df_col(data, 'v56', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bin_df_col()` function takes the 140 cutoff and sets all categories with a value counts below the cutoff to `Other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 269)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### One hot encode\n",
    "data_ohe = pd.get_dummies(data)\n",
    "data_ohe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After binning, the data is one hot encoded such that each of the categories for all categorical features are split into their own binary indicator variable. After one hot encoding, the final feature set consists of 453 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clf_grid(data, clf_hyper_grid, return_best=False, boost_rounds=None, clf=None):\n",
    "    clf_scores = []\n",
    "\n",
    "    param, param_values = zip(*clf_hyper_grid.items())\n",
    "    param_list = [dict(zip(param, param_value)) for param_value in itertools.product(*param_values)]\n",
    "\n",
    "    for params in param_list:\n",
    "        if clf:\n",
    "            score = run_clf(clf, data, params)\n",
    "            clf_scores.append(score)\n",
    "        else:\n",
    "            for boost_round in boost_rounds:\n",
    "                score = run_xgb(data, params, boost_round)\n",
    "                clf_scores.append(score)\n",
    "\n",
    "    clf_scores.sort(key=lambda x: x['log_loss'])\n",
    "    if return_best:\n",
    "        clf_scores = [clf_scores[0]]\n",
    "\n",
    "    return clf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run_clf_grid()` above will be used to tune the hyperparamters of the models used to run the classification. The data is passed along with a dictionary of parameters to tune. The keys of the dictionary are the parameter name and the values are a list of parameter values to try. The itertools.product function is used to generate all possible combinations of parameters and the provided classifier is run using the `run_clf()` function with every parameter combination (if no classifier is provided, xgboost is used). The scores for each parameter combination are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clf(a_clf, data, clf_hyper):\n",
    "    M, L, n_folds = data # unpack data container\n",
    "    kf = KFold(n_splits=n_folds) # Establish the cross validation\n",
    "    scores = []\n",
    "\n",
    "    for ids, (train_index, test_index) in enumerate(kf.split(M, L)):\n",
    "        clf = a_clf(**clf_hyper) # unpack parameters into clf is they exist\n",
    "        clf.fit(M.iloc[train_index], L.iloc[train_index])\n",
    "\n",
    "        pred = clf.predict(M.iloc[test_index])\n",
    "        score_log_loss = log_loss(L.iloc[test_index], pred)\n",
    "        pred[pred<0.5] = 0\n",
    "        pred[pred>=0.5] = 1\n",
    "        score_acc = accuracy_score(L.iloc[test_index], pred)\n",
    "        scores.append((score_log_loss, score_acc))\n",
    "\n",
    "    ret = {\n",
    "        'clf': str(clf),\n",
    "        'log_loss': sum([score[0] for score in scores]) / float(len(scores)),\n",
    "        'accuracy': sum([score[1] for score in scores]) / float(len(scores))\n",
    "    }\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the `run_clf()` called by `run_clf_grid()`. This funciton does k-fold cross validation, unpacks the hyperparamters provided, and passes them to the provided classifier. The classifier is fit on each train fold and the log loss is calculated between the predictions on the test fold and the target labels for each fold. These are averaged to provide the k-fold log loss. \n",
    "\n",
    "The formula for the log loss is LogLoss = - \\frac{1}{n} \\sum\\limits_{i=1}^n [y_i \\cdot log_e(\\hat{y_i}) + (1-y_i) \\cdot log_e(1-\\hat{y_i}) ]\n",
    "where y is the label of the target and smaller is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb(data, clf_hyper, boost_round):\n",
    "    M, L, n_folds = data # unpack data container\n",
    "    kf = KFold(n_splits=n_folds) # Establish the cross validation\n",
    "    scores = []\n",
    "\n",
    "    for ids, (train_index, test_index) in enumerate(kf.split(M, L)):\n",
    "        xgtrain = xgb.DMatrix(M.iloc[train_index].values, L.iloc[train_index].values)\n",
    "        xgtest = xgb.DMatrix(M.iloc[test_index].values, L.iloc[test_index].values)\n",
    "        \n",
    "        clf = xgb.train(\n",
    "            clf_hyper,\n",
    "            xgtrain,\n",
    "            num_boost_round=boost_round,\n",
    "            verbose_eval=True,\n",
    "            maximize=False\n",
    "        )\n",
    "        \n",
    "        pred = clf.predict(xgtest, ntree_limit=clf.best_iteration)\n",
    "        score_log_loss = log_loss(L.iloc[test_index], pred)\n",
    "        pred[pred<0.5] = 0\n",
    "        pred[pred>=0.5] = 1\n",
    "        score_acc = accuracy_score(L.iloc[test_index], pred)\n",
    "        scores.append((score_log_loss, score_acc))\n",
    "\n",
    "    ret = {\n",
    "        'params': clf_hyper,\n",
    "        'boost_round': boost_round,\n",
    "        'log_loss': sum([score[0] for score in scores]) / float(len(scores)),\n",
    "        'accuracy': sum([score[1] for score in scores]) / float(len(scores))\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the the same function for xgboost, which requires processing into its ow data type and has different syntax for fitting the model. We still do k-fold cross validation and average the log loss of the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_hyper = { \n",
    "   \"objective\": [\"binary:logistic\"],\n",
    "   \"booster\": [\"gbtree\"],\n",
    "   \"eval_metric\": [\"logloss\"],\n",
    "   \"eta\": [0.001, 0.01, 0.1], \n",
    "   \"subsample\": [.25, .5],\n",
    "   \"colsample_bytree\": [0.25, 0.5],\n",
    "   \"max_depth\": [2,4]\n",
    "}\n",
    "clf_data = (data_ohe, target, 3)\n",
    "xgb_scores = run_clf_grid(clf_data, xgboost_hyper, boost_rounds=[30,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'objective': 'binary:logistic',\n",
       "  'booster': 'gbtree',\n",
       "  'eval_metric': 'logloss',\n",
       "  'eta': 0.1,\n",
       "  'subsample': 0.5,\n",
       "  'colsample_bytree': 0.5,\n",
       "  'max_depth': 2},\n",
       " 'boost_round': 30,\n",
       " 'log_loss': 0.5169844735199082,\n",
       " 'accuracy': 0.7290552584670231}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_scores[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, XGBoost is run on the data with various parameters with 3 folds using `run_clf_grid()`. XGBoost is an optimized gradient boosting machine. Boosting is a technique where the residual of the model are iteratively run as the new targets of the model so that the model learns from the mistakes of previous iterations. \n",
    "\n",
    "Here XGBoost is run with a deciions tree and the parameters being tuned are:\n",
    "- `eta`: learning rate for how aggressively the boosting adjusts the model between iterations\n",
    "- `subsample`: the percent of the training data to subsample each iteration to avoid overfitting\n",
    "- `colsample_bytree`: the percent of columns that are condisered at each level of the tree\n",
    "- `max_depth`: the maximum depth of the decision tree\n",
    "- `boost_rounds`: how many iterations of boost the model will run\n",
    "\n",
    "Notably, the log loss the the XGBoost for a number of paramter sets is below 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_clf = RandomForestClassifier\n",
    "r_clf_hyper_grid = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_depth': [2, 4],\n",
    "    'max_features': [None, 'sqrt'],\n",
    "}\n",
    "rf_scores = run_clf_grid(clf_data, r_clf_hyper_grid, clf=r_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clf': \"RandomForestClassifier(max_depth=4, max_features='sqrt', n_estimators=10)\",\n",
       "  'log_loss': 8.321923983894372,\n",
       "  'accuracy': 0.7590612002376709},\n",
       " {'clf': \"RandomForestClassifier(max_depth=2, max_features='sqrt')\",\n",
       "  'log_loss': 8.670808589877614,\n",
       "  'accuracy': 0.7489601901366606},\n",
       " {'clf': \"RandomForestClassifier(max_depth=4, max_features='sqrt')\",\n",
       "  'log_loss': 8.670808589877614,\n",
       "  'accuracy': 0.7489601901366606},\n",
       " {'clf': 'RandomForestClassifier(max_depth=2, max_features=None, n_estimators=10)',\n",
       "  'log_loss': 9.00939981450452,\n",
       "  'accuracy': 0.7391562685680334},\n",
       " {'clf': \"RandomForestClassifier(max_depth=2, max_features='sqrt', n_estimators=10)\",\n",
       "  'log_loss': 9.009424044729679,\n",
       "  'accuracy': 0.7391562685680332},\n",
       " {'clf': 'RandomForestClassifier(max_depth=2, max_features=None)',\n",
       "  'log_loss': 9.71743817760218,\n",
       "  'accuracy': 0.7186571598336303},\n",
       " {'clf': 'RandomForestClassifier(max_depth=4, max_features=None)',\n",
       "  'log_loss': 10.056029402229086,\n",
       "  'accuracy': 0.7088532382650029},\n",
       " {'clf': 'RandomForestClassifier(max_depth=4, max_features=None, n_estimators=10)',\n",
       "  'log_loss': 11.092389838822477,\n",
       "  'accuracy': 0.6788472964943554}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next algorithm under considersation is the Random Forest Classifier. Random Forests are also tree base, however they are built in parallel. A number of different decision trees are built using subset of the data and new data is fed to the resulting set of trees and they vote on the new classification.\n",
    "\n",
    "The hyper parameters being tuned are the number of trees, the max depth of the trees, and the number of features considered when looking for a split. \n",
    "\n",
    "The log loss for random forest is consistently in the 7.7-8.25, quite a bit worse than XGBoost above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/msds_rpy37/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_clf = LinearSVC\n",
    "svc_clf_hyper_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'tol': [0.01, 0.0001, 0.00001],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "svc_scores = run_clf_grid(clf_data, svc_clf_hyper_grid, clf=svc_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clf': 'LinearSVC(C=0.1, max_iter=5000)', 'score': 7.920575587348921},\n",
       " {'clf': 'LinearSVC(C=0.1, max_iter=5000, tol=0.01)',\n",
       "  'score': 7.922086031547568},\n",
       " {'clf': 'LinearSVC(C=0.1, max_iter=5000, tol=1e-05)',\n",
       "  'score': 7.92450426562787},\n",
       " {'clf': 'LinearSVC(C=1, max_iter=5000)', 'score': 8.229649398992613},\n",
       " {'clf': 'LinearSVC(C=10, max_iter=5000, tol=0.01)',\n",
       "  'score': 8.324511627323252},\n",
       " {'clf': 'LinearSVC(C=1, max_iter=5000, tol=0.01)',\n",
       "  'score': 12.211253542686412},\n",
       " {'clf': 'LinearSVC(C=1, max_iter=5000, tol=1e-05)',\n",
       "  'score': 12.872297181102917},\n",
       " {'clf': 'LinearSVC(C=10, max_iter=5000, tol=1e-05)',\n",
       "  'score': 13.447533730494486},\n",
       " {'clf': 'LinearSVC(C=10, max_iter=5000)', 'score': 14.099811809806676}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the linear SVC is run. This is the linear version of SVM where linear boundaries seperate the data based on the seperation with the largest margin. The performance in terms of log loss was similar to random forest, but XGBoost was much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_ohe, target, test_size=0.33, random_state=42)\n",
    "xgtrain = xgb.DMatrix(X_train.values, y_train.values)\n",
    "xgtest = xgb.DMatrix(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit the model...\n"
     ]
    }
   ],
   "source": [
    "print('Fit the model...')\n",
    "# XGBoost params:\n",
    "xgboost_params = { \n",
    "   \"objective\": \"binary:logistic\",\n",
    "   \"booster\": \"gbtree\",\n",
    "   \"eval_metric\": \"logloss\",\n",
    "   \"eta\": 0.01, \n",
    "   \"subsample\": 0.5,\n",
    "   \"colsample_bytree\": 0.5,\n",
    "   \"max_depth\": 3\n",
    "}\n",
    "boost_round = 50\n",
    "clf = xgb.train(xgboost_params,xgtrain,num_boost_round=boost_round,verbose_eval=True,maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict...\n",
      "0.5840175097972852\n",
      "0.7726501616922017\n"
     ]
    }
   ],
   "source": [
    "#Make predict\n",
    "print('Predict...')\n",
    "test_preds = clf.predict(xgtest, ntree_limit=clf.best_iteration)\n",
    "print(log_loss(y_test,test_preds))\n",
    "print(accuracy_score(y_test,np.rint(test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
